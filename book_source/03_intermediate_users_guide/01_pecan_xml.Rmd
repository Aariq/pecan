# The PEcAn XML {#pecanXML}

The PEcAn system is configured using a XML file, often called `pecan.xml`.
It contains the following major sections ("nodes"):

- [Core configuration](#xml-core-config)
	- [Top level structure](#xml-structure)
	- [`info`](#xml-info) -- Run metadata
	- [`outdir`](#xml-outdir) -- Output directory
	- [`database`](#xml-database) -- Bety and other database settings
	- [`pft`](#xml-pft) -- Plant functional type selection
	- [`meta.analysis`](#xml-meta-analysis) -- Trait meta analysis
	- [`model`](#xml-model) -- Model configuration
	- [`run`](#xml-run) -- Run setup
- [Advanced features](#xml-advanced)
	- [`ensemble`](#xml-ensemble) -- Ensemble runs
	- [`sensitivity.analysis`](#xml-sensitivity-analysis) -- Sensitivity analysis
	- [`parameter.data.assimilation`](#xml-parameter-data-assimilation) -- Parameter data assimilation
	- (experimental) [`state.data.assimilation`](#xml-state-data-assimilation) -- State data assimilation
	- (experimental) [`browndog`](#xml-browndog) -- Brown Dog configuration
	- (experimental) [`benchmarking`](#xml-benchmarking) -- Benchmarking
	
A basic example looks like this:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<pecan>
  <info>
    <notes>Example run</notes>
    <userid>-1</userid>
	<username>guestuser</username>
    <date>2018/09/18 19:12:28 +0000</date>
  </info>
  <outdir>/data/workflows/PEcAn_99000000006</outdir>
  <database>
    <bety>
      <user>bety</user>
      <password>bety</password>
      <host>postgres</host>
      <dbname>bety</dbname>
      <driver>PostgreSQL</driver>
      <write>true</write>
    </bety>
    <dbfiles>/data/dbfiles</dbfiles>
  </database>
  <pfts>
    <pft>
      <name>tundra.grasses</name> 
      <constants>
        <num>1</num>
      </constants>
    </pft>
  </pfts>
  <meta.analysis>
    <iter>3000</iter>
    <random.effects>FALSE</random.effects>
  </meta.analysis>
  <ensemble>
   <size>1</size>
   <variable>NPP</variable>
   <samplingspace>
   <parameters>
    <method>uniform</method>
   </parameters>
   <met>
    <method>sampling</method>
 	</met>
   </samplingspace>
  </ensemble>
  <model>
    <id>5000000002</id>
  </model>
  <workflow>
    <id>99000000006</id>
  </workflow>
  <run>
    <site>
      <id>1000000098</id>
      <met.start>2004/01/01</met.start>
      <met.end>2004/12/31</met.end>
    </site>
    <inputs>
      <met>
        <source>CRUNCEP</source>
        <output>SIPNET</output>
      </met>
    </inputs>
    <start.date>2004/01/01</start.date>
    <end.date>2004/12/31</end.date>
  </run>
  <host>
    <name>localhost</name>
    <rabbitmq>
      <uri>amqp://guest:guest@rabbitmq:5672/%2F</uri>
      <queue>SIPNET_136</queue>
    </rabbitmq>
  </host>
</pecan>
```

In the following sections, we step through each of these sections in detail.

## Core configuration {#xml-core-config}

### Top-level structure {#xml-structure}

The first line of the XML file should contain version and encoding information. 

```xml
<?xml version="1.0" encoding="UTF-8"?>
```

The rest of the XML file should be surrounded by `<pecan>...</pecan>` tags.

```xml
<pecan>
  ...XML body here...
</pecan>
```

### `info`: Run metadata {#xml-info}

This section contains run metadata.
This information is not essential to a successful model run, but is useful for tracking run provenance. 

```xml
  <info>
    <notes>Example run</notes>
    <userid>-1</userid>
	<username>guestuser</username>
    <date>2018/09/18 19:12:28 +0000</date>
  </info>
```

The `<notes>` tag will be filled in by the web GUI if you provide notes, or you can add notes yourself within these tags. We suggest adding notes that help identify your run and a brief description of what the run is for. Because these notes are searchable within Bety and the PEcAn web interface, they can be a useful way to distinguish between similar runs.

The `<userid>` and `<username>` section is filled in from the GUI if you are signed in. If you are not using the GUI, add the user name and ID you are associated with that exists within the BETY database.

The `<date></date>` tag is filled automatically at the time of your run from the GUI. If you are not using the GUI, add the date you execute the run. This tag is not the tag for the dates you would like to run your model simulation.

### `outdir`: Output directory {#xml-outdir}

The `<outdir>` tag is used to configure the output folder used by PEcAn.
This is the directory where all model input and output files will be stored.
By default, the web interface names this folder `PEcAn_<workflow ID>`, and higher-level location is set by the `$output_folder$` variable in the `web/config.php` file.
If no `outdir` is specified, PEcAn defaults to the working directory from which it is called, which may be counterintuitive.

```xml
  <outdir>/data/workflows/PEcAn_99000000006</outdir>
```

### `database`: Bety and other database settings {#xml-database}

#### `bety`: Bety configuration {#xml-bety}

The `bety` tag defines the driver to use to connect to the database (in 99.9% of 
cases, this should be `PostgreSQL`, the default) and parameters required to connect to the database. Note that connection parameters are passed *exactly* as entered to the underlying R database driver, and any invalid or extra parameters will result in an error.

In other words, this configuration...

```xml
  <database>
	...
    <bety>
      <user>bety</user>
      <password>bety</password>
      <host>postgres</host>
      <dbname>bety</dbname>
      <driver>PostgreSQL</driver>
      <write>true</write>
    </bety>
	...
  </database>
```

...will be translated into R code like the following:

```r
con <- DBI::dbConnect(
  DBI::dbDriver("PostgreSQL"),
  user = "bety",
  password = "bety",
  dbname = "bety",
  host = "postgres",
  write = TRUE
)
```

Common parameters are described as follows:

* `driver`: The driver to use to connect to the database. This should always be set to `PostgreSQL`, unless you absolutely know what you're doing.
* `dbname`: The name of the database (formerly `name`), corresponding to the `-d` argument to `psql`. In most cases, this should be set to `bety`, and will only be different if you named your Bety instance something else (e.g. if you have multiple instances running at once). If unset, it will default to the user name of the current user, which is usually wrong!
* `user`: The username to connect to the database (formerly `userid`), corresponding to the `-U` argument to `psql`. default value is the username of the current user logged in (PostgreSQL uses user for this field).
* `password`: The password to connect to the database (was `passwd`), corresponding to the `-p` argument to `psql`. If unspecified, no password is used. On standard PEcAn installations, the username and password are both `bety` (all lowercase).
* `host`: The hostname of the `bety` database, corresponding to the `-h` argument to `psql`. On the VM, this will be `localhost` (the default). If using `docker`, this will be the name of the PostgreSQL container, which is `postgres` if using our standard `docker-compose`. If connecting to bety on a remote server (e.g. `psql-pecan.bu.edu`), this should be the same as the hostname used for `ssh` access.
* `write`: Logical. If `true` (the default), write results to the database. If `false`, PEcAn will run but will not store any information to `bety`.

When using the web interface, this section is configured by the `web/config.php` file.
The default `config.php` settings on any given platform (VM, Docker, etc.) or in example files (e.g. `config.php.example`) are a good place to get default values for these fields if writing `pecan.xml` by hand.

Key R functions using these parameters are as follows:

- `PEcAn.DB::db.open` -- Open a Bety connection and create a connection object, which is used by many other functions for communicating with Bety.

#### `dbfiles`: Location of database files {#xml-dbfiles}

The `dbfiles` is a path to the local location of files needed to run models using PEcAn, including model executables and inputs.

```xml
  <database>
	...
    <dbfiles>/data/dbfiles</dbfiles>
	...
  </database>
```

#### (Experimental) `fia`: FIA database connection parameters {#xml-fia}

If a version of the FIA database is available, it can be configured using `<fia>` node, whose syntax is identical to that of the `<bety>` node.

```xml
  <database>
    ...
	<fia>
		<dbname>fia5data</dbname>
		<username>bety</username>
		<password>bety</password>
		<host>localhost</host>
	</fia>
	...
  </database>
```

Currently, this is only used for extraction of specific site vegetation information (notably, for ED2 `css`, `pss`, and `site` files).
Stability not ensured as of 1.5.3.

### `pft`: Plant functional type selection {#xml-pft}

The PEcAn system requires at least 1 plant functional type (PFT) to be specified inside the `<pfts>` section. 

```xml
  <pfts>
    <pft>
      <name>tundra.grasses</name> 
      <constants>
        <num>1</num>
      </constants>
    </pft>
  </pfts>
```

* `name` : (required) the name of the PFT, which must *exactly* match the name in Bety.
* `outdir`: (optional) Directory path in which PFT-specific output will be stored during meta-analysis and sensitivity analysis. If not specified (recommended), it will be written into `<outdir>/<pftname>`.
* `contants`: (optional) this section contains information that will be written directly into the model specific configuration files. For example, some models like ED2 use PFT numbers instead of names for PFTs, and those numbers can be specified here. See documentation for model-specific code for details.

This information is currently used by the following PEcAn workflow function:

- `get.traits` - ??????

### `meta.analysis`: Trait Meta Analysis {#xml-meta-analysis}

The section meta.analysis needs to exists for a meta.analysis to be executed, even though all tags inside are optional.
Conversely, if you do not want to do a trait meta-analysis (e.g. if you want to manually set all parameters), you should omit this node.

```xml
  <meta.analysis>
    <iter>3000</iter>
    <random.effects>FALSE</random.effects>
  </meta.analysis>
```

Some of the tags that can go in this section are:

* `iter`: [MCMC](http:/en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) (Markov Chain Monte Carlo) chain length, i.e. the total number of posterior samples in the meta-analysis, default is 3000. Smaller numbers will run faster but produce larger errors.
* `random.effects`: Whether to include random effects (site, treatment) in meta-analysis model. Can be set to FALSE to work around convergence problems caused by an over parameterized model (e.g. too many sites, not enough data). The default value is TRUE.
* `update`: Should previous results of meta.analysis and get.traits be re-used. If set to TRUE the meta-analysis and get.trait.data will always be executed. Setting this to FALSE will try and reuse existing results. Future versions will allow for AUTO as well which will try and reuse if the PFT/traits have not changed. The default value is FALSE.
* `threshold`: threshold for Gelman-Rubin convergence diagnostic (MGPRF); default is 1.2.

This information is currently used by the following PEcAn workflow function:

- `PEcAn.MA::run.meta.analysis` - ???

### `model`: Model configuration {#xml-model}

This section is required and tells PEcAn what model to run. This section should either specify `<id>` or both `<name>` and `<binary>`  of the model. If both id and name and/or binary are specified the id is used to check the specified name and/or binary.

As of version 1.3.7 the `<name>` tag has been renamed `<type>`. The `<type>` tag refers to the "type" of model and is used for a) identifying appropriate pfts and b) identifying whether appropriate inputs (i.e. met data) are available for the given site and model (or if they can be created). 

To ensure compatability, the code will automatically convert from `<name>` to `<type>`.

#### functions: 

`write.configs()`, `run.models()`

#### tags

```xml
<model>
	<id>7</id>
	<type>ED2</type>
	<binary>/usr/local/bin/ed2.r82</binary>
	<job.sh>module load hdf5</job.sh>
	<config.header>
		<!--...xml code passed directly to config file...-->
	</config.header>
</model>
```

* **id** : [optional/required] id in the models database table, see above.  
* **name** : **OBSOLETE** name of the model, use type from version 1.3.7
* **type** : [optional/required] type of model, see above.
* **binary** : [optional/required] path to the model executable, see above.  
* **job.sh** : [optional] additional options to add to the job.sh at the top  
* **config.headers** : [optional] XML that will appear at the start of generated config files.

#### Model-specific configuration {#xml-model-specific}

See the following:

* [ED2][ED2 Configuration]
* [SIPNET][SIPNET Configuration]
* [BIOCRO][BioCro Configuration]

#### ED2 specific tags {#xml-ed}

Following variables are ED specific and are used in the [ED2 Configuration](ED2-Configuration).

Starting at 1.3.7 the tags for inputs have moved to `<run><inputs>`. This includes, veg, soil, psscss, inputs.

```xml
	<edin>/home/carya/runs/PEcAn_4/ED2IN.template</edin>
	<config.header>
		<radiation>
			<lai_min>0.01</lai_min>
		</radiation>
		<ed_misc>
			<output_month>12</output_month>
		</ed_misc> 
	</config.header>
	<phenol.scheme>0</phenol.scheme>
```

  
* **edin** : [required] template used to write ED2IN file
* **veg** : **OBSOLETE** [required] location of VEG database, now part of `<run><inputs>`
* **soil** : **OBSOLETE** [required] location of soild database, now part of `<run><inputs>`
* **psscss** : **OBSOLETE** [required] location of site inforation, now part of `<run><inputs>`. Should be specified as `<pss>`, `<css>` and `<site>`.
* **inputs** : **OBSOLETE** [required] location of additional input files (e.g. data assimilation data), now part of `<run><inputs>`. Should be specified as `<lu>` and `<thsums>`.

### `run`: Run Setup {#xml-run}

#### tags

```xml
<run>
	<jobtemplate>/home/carya/path/to/template</jobtemplate>
	<start.date>2002-01-01 00:00:00</start.date>
	<end.date>2005-12-31 00:00:00</end.date>
	</dbfiles>/home/carya/.pecan/dbfiles</dbfiles>
	<site>
		<id>772</id>
		<name>Niwot Ridge Forest/LTER NWT1 (US-NR1)</name>
		<lat>40.032900</lat>
		<lon>-105.546000</lon>
		<met.start>2002/01/01</met.start>
		<met.end>2005/12/31</met.end>
	</site>
	<inputs>
          <met>
             <id>10000000001</id>
             <path>/fs/data1/pecan.data/input/</path>
             <source>Ameriflux</source>
             <username>carya</username>
          </met>
	</inputs>
</run>
<host>
		<name>localhost</name>
		<rundir>/home/carya/testrun.pecan/run/</rundir>
		<outdir>/home/carya/testrun.pecan/out/</outdir>
		<scratchdir>/tmp/carya</scratchdir>
		<clearscratch>TRUE</clearscratch>
		<qsub>qsub -N @NAME@ -o @STDOUT@ -e @STDERR@ -S /bin/bash</qsub>
		<qsub.jobid>Your job ([0-9]+) .*</qsub.jobid>
		<qstat>qstat -j @JOBID@ &> /dev/null || echo DONE</qstat>
		<job.sh>module load udunits R/R-3.0.0_gnu-4.4.6</job.sh>
</host>
```

* **jobtemplate** : [optional] the template used when creating a job.sh file which is used to launch the actual model. Each model has it's own [template](https://github.com/PecanProject/pecan/blob/master/models/ed/inst/template.job) in the inst folder of the module. The following variables can e used: @SITE_LAT@, @SITE_LON@, @SITE_MET@, @START_DATE@, @END_DATE@, @OUTDIR@, @RUNDIR@ which all come variables in the pecan.xml file. The following two command can be used to copy and clean the results from a scratch folder (specified as scratch in the run section below, for example local disk vs network disk) : @SCRATCH_COPY@, @SCRATCH_CLEAR@ .
* **start.date** : [required] the first day of the simulation  
* **end.date** : [required] the last day of the simulation
* **dbfiles** : [optional] location where pecan should write files that will be stored in the database. The default is store them in `${HOME}/.pecan/dbfiles`

Site specific information is specified in the `<site>` subsection. Either `<id>` or `<name>`, `<lat>` and `<lon>` should be specified. If id and any of the others are specified the values will be compared with those from BETYdb.
 
* **id** : [optional/required] id of the site in the BETY database, see above.  
* **name** : [optional/required] site name, see above.  
* **lat** : [optional/required] site latitude, see above.  
* **lon** : [optional/required] site longitude, see above.  

Inputs specific information for each model type is specified in the `<inputs>` subsection. 
Each input will have three tags:
* **id** :  [optional/required] An id that points to the input if already in the database.
* **path** : [optional/required] The path to the dataset if already downloaded.
* **source** : [optional/required] The input data type. This tag name needs to match the names in the conversion functions. 
In general, the path should be filled in by PEcAn and not by the user.
If PEcAn is processing all the input, id is not required. Alternatively, if you're using data processed by hand, source is not required. 


One common input will be the weather data, often specified in `<met>`.

Other model types will have different model specific inputs.  PEcAn will find the location of the file on the host you run PEcAn on.

* **met** : [model type specific] most models will have a met tag to specify location of the weather data.
* **pss** : [ED2, required] location of patch file
* **css** : [ED2, required] location of cohort file
* **site** : [ED2, optional] location of site file
* **lu** : [ED2, required] location of land use file
* **thsums** : [ED2, required] location of thermal sums file
* **veg** : [ED2, required] location of vegetation data
* **soil** : [ED2, required] location of soil data

Host on which the simulation will run is specified in the `<host>` subsection. If this section is not specified it is assumed the simulation will run on localhost. If qsub is specified (can be empty in which case the defaults will be used) the models will be executed using qsub.

* **name** : [optional] name of host server where model is located and executed, if not specified localhost is assumed.  
* **rundir** : [optional/required] location where all the configuration files are written. For localhost this is optional (`<outdir>/run` is the default), for any other host this is required.  
* **outdir** : [optional/required] location where all the outputs of the model are written. For localhost this is optional (`<outdir>/out` is the default), for any other host this is required.
* **scratchdir** : [optional] location where output is written. If specified the output from the model is written to this folder and copied to the outdir when the model is finished, this could significantly speed up the model execution (by using local or ram disk).
* **clearscratch** : [optional] if set to TRUE the scratchfolder is cleaned up after copying the results to the outdir, otherwise the folder will be left. The default is to clean up after copying.
* **qsub** : [optional] the command to submit a job to the queuing system. There are 3 parameters you can use when specifying the qsub command, you can add additional values for your specific setup (for example -l walltime to specify the walltime, etc). You can specify @NAME@ the pretty name, @STDOUT@ where to write stdout and @STDERR@, where to write stderr. You can specify an empty element (<qsub/>) in which case it will use the default value is "qsub -V -N @NAME@ -o @STDOUT@ -e @STDERR@ -s /bin/bash".
* **qsub.jobid** : [optional] the regular expression used to find the jobid returned from qsub. If not specified (and qsub is) it will use the default value is "Your job ([0-9]+) .*"
* **qstat** : [optional] the command to execute to check if a job is finished, this should return DONE if the job is finished. There is one parameter this command should take @JOBID@ which is the id of the job as returned by qsub.jobid. If not specified (and qsub is) it will use the default value is "qstat -j @JOBID@ || echo DONE"
* **job.sh** : [optional] additional options to add to the job.sh at the top  

## Advanced features {#xml-advanced}

### `ensemble`: Ensemble Runs {#xml-ensemble}

As with `meta.analysis`, if this section is missing, then PEcAn will not do an ensemble analysis.

```xml
  <ensemble>
   <size>1</size>
   <variable>NPP</variable>
   <samplingspace>
   <parameters>
    <method>uniform</method>
   </parameters>
   <met>
    <method>sampling</method>
 	</met>
   </samplingspace>
  </ensemble>
```

An alternative configuration is as follows:

```xml
<ensemble>
  <size>5</size>
  <variable>GPP</variable>
  <start.year>1995</start.year>
  <end.year>1999</end.year>
  <samplingspace>
  <parameters>
    <method>lhc</method>
  </parameters>
  <met>
    <method>sampling</method>
  </met>
  </samplingspace>
</ensemble>
```

* `size` : (required) the number of runs in the ensemble.
* `variable`: (optional) name of one (or more) variables the analysis should be run for. If not specified, `sensitivity.analysis` variable is used, otherwise default is GPP (Gross Primary Productivity).
* `samplingspace`: (optional) Contains tags for defining how the ensembles will be generated.

Each piece in the sampling space can potentially have a method tag and a parent tag. Method refers to the sampling method and parent refers to the cases where we need to link the samples of two components. When no tag is defined for one component, one sample will be generated and used for all the ensembles. This allows for partitioning/studying different sources of uncertainties. For example, if no met tag is defined then, one met path will be used for all the ensembles and as a result the output uncertainty will come from the variability in the parameters. At the moment no sampling method is implemented for soil and vegetation.
Available sampling methods for `parameters` can be found in the documentation of the `PEcAn.utils::get.ensemble.samples` function.
For the cases where we need simulations with a predefined set of parameters, met and initial condition we can use the restart argument. Restart needs to be a list with name tags of `runid`, `inputs`, `new.params` (parameters), `new.state` (initial condition), `ensemble.id` (ensemble ids), `start.time`, and `stop.time`.

The restart functionality is developed using model specific functions by called `write_restart.modelname`. You need to make sure first that this function is already exist for your desired model.

Note: if the ensemble size is set to 1, PEcAn will select the **posterior median** parameter values rather than taking a single random draw from the posterior

This information is currently used by the following PEcAn workflow functions:

- `write.configs` - ???
- `write.ensemble.configs` - ???
- `run.ensemble.analysis()` - ???

### `sensitivity.analysis`: Sensitivity analysis {#xml-sensitivity-analysis}

Only if this section is defined a sensitivity analysis is done. This section will have `<quantile>` or `<sigma>` nodes. If neither are given, the default is to use the median +/- [1 2 3] x sigma (e.g. the 0.00135 0.0228 0.159 0.5 0.841 0.977 0.999 quantiles); If the 0.5 (median) quantile is omitted, it will be added in the code.

#### tags

```xml
<sensitivity.analysis>
	<quantiles>
		<quantile></quantile>
		<sigma>-3</sigma>
		<sigma>-2</sigma>
		<sigma>-1</sigma>
		<sigma>1</sigma>
		<sigma>2</sigma>
		<sigma>3</sigma>
	</quantiles>
  <variable>GPP</variable>
  <perpft>TRUE</perpft>
	<start.year>2004</start.year>
	<end.year>2006</end.year>
</sensitivity.analysis>
```

* `quantiles` : [optional] Quantiles of parameter distributions at which the model should be evaluated when running sensitivity analysis. Values greater than 0 and less than 1 can be used.
* `sigma` : [optional] Any real number can be used to indicate the quantiles to be used in units of normal probability.
* `quantile` : [optional] Which quantile should be used.
* `start.date` : [required?] start date of the sensitivity analysis (in YYYY/MM/DD format) 
* `end.date` : [required?] end date of the sensitivity analysis (in YYYY/MM/DD format)
* **_NOTE:_** start.date and end.date are distinct from values set in the run tag because this analysis can be done over a subset of the run.
*  `variable` : [optional] name of one (or more) variables the analysis should be run for. If not specified, sensitivity.analysis variable is used, otherwise default is GPP.
* `perpft` : [optional] if `TRUE` a sensitivity analysis on PFT-specific outputs will be run. This is only possible if your model provides PFT-specific outputs for the `variable` requested. This tag only affects the output processing, not the number of samples proposed for the analysis nor the model execution.

This information is currently used by the following PEcAn workflow functions:

- `write.configs()` - ???
- `run.sensitivity.analysis()` - ???

### Parameter Data Assimilation {#xml-parameter-data-assimilation}

The following tags can be used for state data assimilation. More detailed information can be found here: [Parameter Data Assimilation Documentation](pda.documentation.md)

#### tags

Coming soon...

### (experimental) State Data Assimilation {#xml-state-data-assimilation}

The following tags can be used for state data assimilation. More detailed information can be found here: [State Data Assimilation Documentation](sda.documentation.md)

```xml
<state.data.assimilation>
	<process.variance>FALSE</process.variance>
  <sample.parameters>FALSE</sample.parameters>
  <state.variables>
   <variable>AGB.pft</variable>
   <variable>TotSoilCarb</variable>
  </state.variables>
  <spin.up>
  	<start.date>2004/01/01</start.date>
	  <end.date>2006/12/31</end.date>
  </spin.up>
  <forecast.time.step>1</forecast.time.step>
	<start.date>2004/01/01</start.date>
	<end.date>2006/12/31</end.date>
</state.data.assimilation>
```

* **process.variance** : [optional] TRUE/FLASE flag for if process variance should be estimated (TRUE) or not (FALSE). If TRUE, a generalized ensemble filter will be used. If FALSE, an ensemble Kalman filter will be used. Default is FALSE.
* **sample.parameters** : [optional] TRUE/FLASE flag for if parameters should be sampled for each ensemble member or not. This allows for more spread in the intial conditions of the forecast.
* **_NOTE:_** If TRUE, you must also assign a vector of trait names to pick.trait.params within the sda.enkf function.
* **state.variable** : [required] State variable that is to be assimilated (in PEcAn standard format). Default is "AGB" - Above Ground Biomass.
* **spin.up** : [required] start.date and end.date for model spin up.
* **_NOTE:_** start.date and end.date are distinct from values set in the run tag because spin up can be done over a subset of the run.
* **forecast.time.step** : [optional] start.date and end.date for model spin up.
* **start.date** : [required?] start date of the state data assimilation (in YYYY/MM/DD format) 
* **end.date** : [required?] end date of the state data assimilation (in YYYY/MM/DD format)
* **_NOTE:_** start.date and end.date are distinct from values set in the run tag because this analysis can be done over a subset of the run.

### (experimental) Brown Dog {#xml-browndog}

This section describes how to connect to [Brown Dog](http://browndog.ncsa.illinois.edu). This facilitates processing and conversions of data (currently only meteorological input data).

```xml
  <browndog>
	<url>...</url>
	<username>...</username>
	<password>...</password>
  </browndog>
```

* `url`: (required) endpoint for Brown Dog to be used.
* `username`: (optional) username to be used with the endpoint for Brown Dog.
* `password`: (optional) password to be used with the endpoint for Brown Dog.

This information is currently used by the following R functions:

- `PEcAn.data.atmosphere::met.process` -- Generic function for processing meteorological input data.

### (experimental) Benchmarking {#xml-benchmarking}

Coming soon...

